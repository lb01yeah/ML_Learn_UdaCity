{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 监督学习模型\n",
    "### 问题 2 - 模型应用\n",
    "\n",
    "你能够在 [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html) 中选择以下监督学习模型\n",
    "- 高斯朴素贝叶斯 (GaussianNB)\n",
    "- 决策树 (DecisionTree)\n",
    "- 集成方法 (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K近邻 (K Nearest Neighbors)\n",
    "- 随机梯度下降分类器 (SGDC)\n",
    "- 支撑向量机 (SVM)\n",
    "- Logistic回归（LogisticRegression）\n",
    "\n",
    "从上面的监督学习模型中选择三个适合我们这个问题的模型，并回答相应问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型1\n",
    "\n",
    "**模型名称**\n",
    "\n",
    "回答：LogisticRegression\n",
    "\n",
    "**描述一个该模型在真实世界的一个应用场景。（你需要为此做点研究，并给出你的引用出处）**\n",
    "回答：\n",
    ">- 预测是否是某类病情的概率（预测一个婴儿为低体重出生儿的概率）  \n",
    "[低体重出生婴儿的概率](https://www.jianshu.com/p/7af75a684309)\n",
    "\n",
    "**这个模型的优势是什么？他什么情况下表现最好？**\n",
    "回答：\n",
    "> **优势**\n",
    "- 实现简单，广泛的应用于工业问题上；\n",
    "- 分类时计算量非常小，速度很快，存储资源低；\n",
    "- 输出值自然地落在0到1之间，便利的观测样本概率分数；\n",
    "- 对逻辑回归而言，多重共线性并不是问题，它可以结合L2正则化来解决该问题；\n",
    ">**什么情况下表现最好\n",
    "- 特征相对独立，特征数据不是很多。\n",
    "\n",
    "\n",
    "**这个模型的缺点是什么？什么条件下它表现很差？**  \n",
    "回答：  \n",
    "> **缺点：**  \n",
    "- 当特征空间很大时，逻辑回归的性能不是很好；\n",
    "- 容易欠拟合，一般准确度不太高\n",
    "- 不能很好地处理大量多类特征或变量；\n",
    "- 只能处理两分类问题，且必须线性可分；\n",
    "- 不能很好处理特征之间相关的情况；  \n",
    "\n",
    "> **什么条件下它表现很差？：**  \n",
    "在特征很多，数据非线性，以及特征之间关联性很强时表现出差别很大\n",
    "\n",
    "**根据我们当前数据集的特点，为什么这个模型适合这个问题。**\n",
    "回答：\n",
    "- 数据集的特征适量且很清晰，且特征有相对的独立性。能够为函数找到最合适的参数，使得函数的值和样本的值最接近。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型2\n",
    "\n",
    "**模型名称**\n",
    "\n",
    "回答：决策树 (DecisionTree)\n",
    "\n",
    "**描述一个该模型在真实世界的一个应用场景。（你需要为此做点研究，并给出你的引用出处）**\n",
    "回答：\n",
    ">- 预测是否是某类病情的概率（预测一个婴儿为低体重出生儿的概率）  \n",
    "[提高产品销量](https://www.cnblogs.com/jiangzhonglian/p/7690033.html)\n",
    "\n",
    "**这个模型的优势是什么？他什么情况下表现最好？**\n",
    "回答：\n",
    "> **优势**\n",
    "- 实现简单，广泛的应用于工业问题上；\n",
    "- 分类时计算量非常小，速度很快，存储资源低；\n",
    "- 输出值自然地落在0到1之间，便利的观测样本概率分数；\n",
    "- 对逻辑回归而言，多重共线性并不是问题，它可以结合L2正则化来解决该问题；\n",
    ">**什么情况下表现最好\n",
    "- 特征相对独立，特征数据不是很多。\n",
    "\n",
    "\n",
    "**这个模型的缺点是什么？什么条件下它表现很差？**  \n",
    "回答：  \n",
    "> **缺点：**  \n",
    "- 当特征空间很大时，逻辑回归的性能不是很好；\n",
    "- 容易欠拟合，一般准确度不太高\n",
    "- 不能很好地处理大量多类特征或变量；\n",
    "- 只能处理两分类问题，且必须线性可分；\n",
    "- 不能很好处理特征之间相关的情况；  \n",
    "\n",
    "> **什么条件下它表现很差？：**  \n",
    "在特征很多，数据非线性，以及特征之间关联性很强时表现出差别很大\n",
    "\n",
    "**根据我们当前数据集的特点，为什么这个模型适合这个问题。**\n",
    "回答：\n",
    "- 数据集的特征适量且很清晰，且特征有相对的独立性。能够为函数找到最合适的参数，使得函数的值和样本的值最接近。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/zhzhl202/article/details/8197109\n",
    "https://www.cnblogs.com/jiangzhonglian/p/7690033.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
