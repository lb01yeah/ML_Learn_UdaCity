{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL强化学习\n",
    "#### RL应用资源\n",
    "- 了解指导仿真机器人如何行走的[研究](https://classroom.udacity.com/nanodegrees/nd009-cn-advanced/parts/18095af6-5771-4af8-8e34-e9597cb3d07a/modules/5078c58c-2218-4773-b566-ac68ee5eb95d/lessons/2942b8b9-76c1-451d-879c-3d31d3ac00c8/concepts/(https://deepmind.com/blog/producing-flexible-behaviours-simulated-environments/)  \n",
    "- 要了解应用于金融领域的强化学习示例，请参阅这个[最终项目](https://github.com/ucaiado/QLearning_Trading)，该项目的作者是一位毕业于机器学习工程师纳米学位的学员。\n",
    "\n",
    "- 了解[电信](https://papers.nips.cc/paper/1740-low-power-wireless-communication-via-reinforcement-learning.pdf)强化学习\n",
    "\n",
    "- 阅读这篇介绍库存管理强化学习的[论文](http://t.cn/RDfyEan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAi Gym\n",
    "是一款开源工具包，用于开发和比较RL算法。使用该工具包中提供的四种环境：  \n",
    "1) frozen lake environment\n",
    "冰冻湖泊环境，编写一个agent(智能体)，它能够到处行走，并且不会跌落到冰冻湖泊的裂缝中。\n",
    "2) 玩二十一点的智能体 agent to play blackjack\n",
    "3)一个有巨大悬崖的小环境 a large cliff  \n",
    "  目标是不会跌落到悬崖中。  \n",
    "4)a taxi world 出租车环境  \n",
    "训练出租车尽可能快的接送乘客  \n",
    "\n",
    "  OpenAi Gym的优势是可以记录你的性能，刚开始agent可能比较随机，经过训练将会发现，可以按照更加智能的方式选择动作。  \n",
    "\n",
    "你不需要在你的计算机上安装 OpenAI Gym，你可以在课堂里完成所有的编程实现过程。你可以通过查看该 [GitHub 代码库](https://github.com/openai/gym)详细了解 OpenAI Gym。\n",
    "\n",
    "建议你花时间查看 [leaderboard](https://github.com/openai/gym/wiki/Leaderboard)，其中包含每个任务的最佳解决方案。\n",
    "\n",
    "请参阅此[博客帖子](https://blog.openai.com/openai-gym-beta/)，详细了解如何使用 OpenAI Gym 加速强化学习研究。\n",
    "\n",
    "安装说明 （可选）  \n",
    "如果你想在你的计算机上安装 OpenAI Gym，建议你完成以下简单安装过程：  \n",
    ">git clone https://github.com/openai/gym.git  \n",
    "cd gym  \n",
    "pip install -e .  \n",
    "\n",
    "安装 OpenAI Gym 后，请获取经典控制任务（例如“CartPole-v0”)的代码：  \n",
    ">pip install -e '.[classic_control]'  \n",
    "\n",
    "最后，通过运行在 examples 目录中提供的简单的[随机智能体](https://github.com/openai/gym/blob/master/examples/agents/random_agent.py)检查你的安装情况。\n",
    ">cd examples/agents  \n",
    "python random_agent.py  \n",
    "\n",
    "（这些说明摘自该 GitHub 代码库 中的自述文件。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 资源\n",
    "在这门课程中，我们将摘录这本[关于强化学习的经典教科书](https://s3.cn-north-1.amazonaws.com.cn/static-documents/nd101/MLND+documents/suttonbookdraft2018jan1.pdf)中的章节。\n",
    "\n",
    "注意，所有建议的阅读资料都是可选阅读内容！\n",
    "\n",
    "请参阅此 [GitHub 代码库](https://github.com/ShangtongZhang/reinforcement-learning-an-introduction)以查看该教科书中的大多数图表的 Python 实现。\n",
    "\n",
    "在学习下节课之前，建议你阅读该教科书的[第一章节](https://s3.cn-north-1.amazonaws.com.cn/static-documents/nd101/MLND+documents/suttonbookdraft2018jan1.pdf)（尤其是第 1.1-1.4 部分），以便了解关于强化学习领域的背景知识。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 参考指南\n",
    "建议你下载[此表格](https://github.com/udacity/rl-cheatsheet/blob/master/cheatsheet.pdf)，其中包含我们将在这门课程中使用的所有记法和算法。请仅将此表格作为你的笔记补充内容！:)\n",
    "\n",
    "你还可以在[该教科书](https://s3.cn-north-1.amazonaws.com.cn/static-documents/nd101/MLND+documents/suttonbookdraft2018jan1.pdf)第一章节之前的页面中找到另一个实用记法指南。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
