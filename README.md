# ML_Learn_UdaCity
  Code highlights in learning process
课程讲解过程中重要code collection

- init( clone with https)  
git clone https://github.com/lb01yeah/ML_Learn_UdaCity.git  
git add .  
git commit -m ""  
git push -u origin master 

二、目录介绍
01机器学习基础
02监督学习 supervised learning
 - L2_PLA(PerceptonLearningAlgorithm-感知器学习算法)

 - L3 决策树Decision_Trees

 - L4 Naive bayes

 - L5 SVM

 - L6 集成学习方法Bagging 和 Adaboost

03 非监督学习Unsupervised_learning
 - L1 聚类cluster 
   KMeans K-均值聚类
 - L2 聚类Lab project
   使用KMeans对电影评级聚类，并使用聚类提供电影推荐
 - L3 层次聚类(hierarchical clustering)
    密度聚类density clustering（DBSCAN）
 - L4 高斯混合模型(Gaussian Mixture Model Clustering)
    聚类验证(Cluster Validation)
    验证指标
 - L5 特征缩放Feature_Scaling
 - L6 PCA（主成分分析）
 - L7 PCA迷你项目
     人脸识别
 - L8 随机投影与ICA（独立成分分析）
 - L9 评估与总结
 - L10 [项目]创建客户细分
 
 04 深度学习DL
  - L1 神经网络
    对逻辑回归、梯度下降、神经网络构建
  - L2 DNN深度神经网络
    深入了解反向传播和神经网络的训练过程、包括改善训练的技巧
  - L3 CNN卷积神经网络
    Alexis解释了卷积神经网络的原理以及此类网络可以如何帮助我们显著改善图片分类的效果
  - L4 癌症检测深度学习
    敏感性、特异性
    ROC曲线
    混淆矩阵
    小项目口袋医生
  - L5 评价与总结
  
  - L6 [项目]小狗图片检测分类
 
 05 强化学习Reinforcement learning
 - L1 强化学习概述
   作为一种机器学习方法，其中机器或软件智能体会学习如何最大化在某个任务中的性能。
   
 - L2 强化学习框架：问题
   了解如何以数学方式将任务构建为markov决策流程
 - L3 强化学习框架：解决方案
   在强化学习中，智能体学习根据与不同结果相关的奖励和惩罚优先选择不同的决策。
 -L4 动态规划
    动态规划设置是解决强化学习问题的第一个实用步骤
 - L5 蒙特卡洛方法
    编写蒙特卡洛控制方法的实现代码，指导智能体玩二十一点！
 - L6 时间差分方法
    学习如何应用时间差分方法(Sarsa,Q学习和预期)解决阶段性任务和连续性任务。
 - L7 迷你项目：解决OpenAi Gym的Taxi-v2任务
    现在已经掌握了强化学习技巧，可以使用OpenAI Gym探索一个迷你项目。
 - L8 机器人走迷宫
    应用Q-learning算法完成一个景点的markov决策问题--走迷宫
    
  
 

